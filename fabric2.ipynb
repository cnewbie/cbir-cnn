{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (16.0, 16.0)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from cbir.model import get_model\n",
    "from cbir.features import extract_raw_features\n",
    "from cbir.utils import load_image, get_list, load_npy_files, covert_data_format\n",
    "from cbir.utils import run_feature_processing_pipeline, get_list_set\n",
    "from cbir.utils import result_ap, result_precision, compute_ap\n",
    "from cbir.crow import apply_crow_aggregation\n",
    "from cbir.rmac import apply_rmac_aggregation\n",
    "from cbir.pwa import PWA, get_discriminative_fm\n",
    "from cbir.query import compute_cosin_distance, simple_query_expansion\n",
    "\n",
    "model = get_model()\n",
    "dataset_img_path='/home/jy/dataset/fabric2'\n",
    "raw_out_path='/home/jy/results/fabric2/raw'\n",
    "crow_out_path='/home/jy/results/fabric2/crow'\n",
    "rmac_out_path='/home/jy/results/fabric2/rmac'\n",
    "pwa_out_path='/home/jy/results/fabric2/pwa'\n",
    "gt_file_path = '/home/jy/dataset/gt_fabric2.txt'\n",
    "#query_img_path = '/home/jy/dataset/fabric2'\n",
    "query_file_path = '/home/jy/dataset/query_fabric2.txt'\n",
    "query_out_path='/home/jy/results/fabric2/query'\n",
    "target_size=(512,512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "dataset_img_list = get_list(dataset_img_path)\n",
    "print(len(dataset_img_list))\n",
    "\n",
    "def extract_features(model, img_list, output_path, extract_function = None, save_raw = True,\\\n",
    "                    save_features = True):\n",
    "    pass\n",
    "    if len(output_path) > 1:\n",
    "        raw_out_path, out_path = output_path\n",
    "    else:\n",
    "        raw_out_path = output_path[0]\n",
    "    \n",
    "    #check dir is exist\n",
    "    if not os.path.exists(raw_out_path):\n",
    "        os.makedirs(raw_out_path)\n",
    "    for i in img_list:\n",
    "        img = load_image(i,target_size)\n",
    "        raw_feature = extract_raw_features(model,img)\n",
    "        if save_raw:\n",
    "            np.save(os.path.join(raw_out_path,os.path.basename(i).split('.')[0]), raw_feature)\n",
    "        if save_features:\n",
    "            cvt_raw_feature = covert_data_format(raw_feature)\n",
    "            out_feature = extract_function(cvt_raw_feature)\n",
    "            np.save(os.path.join(out_path,os.path.basename(i).split('.')[0]), out_feature)\n",
    "\n",
    "#extract raw features\n",
    "extract_features(model, dataset_img_list, (raw_out_path, ), save_features = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 200\n"
     ]
    }
   ],
   "source": [
    "#query list\n",
    "def read_annotation(path):\n",
    "    out_dict = dict()\n",
    "    if not os.path.exists(path):\n",
    "        return out_dict\n",
    "    with open(path) as f:\n",
    "        for i in f:\n",
    "            a,b = i.strip().split(' ')\n",
    "            out_dict[a] = b\n",
    "    return out_dict\n",
    "#read query file \n",
    "query_dict = read_annotation(query_file_path)\n",
    "gt_dict = read_annotation(gt_file_path)\n",
    "print(len(query_dict), len(gt_dict))\n",
    "def get_train_dict(gt, q):\n",
    "    out_dict = dict()\n",
    "    for k, v in gt.items():\n",
    "        if k in q:\n",
    "            pass\n",
    "        else:\n",
    "            out_dict[k] = v\n",
    "    return out_dict\n",
    "\n",
    "train_dict = get_train_dict(gt_dict, query_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful loading of npy file !!!\n",
      "train features shape (150, 12288)\n"
     ]
    }
   ],
   "source": [
    "#get discrimnate features\n",
    "def file_dict_to_list(d, path, ext = '.npy'):\n",
    "    out_list = list()\n",
    "    if d is not None and len(d):\n",
    "        for k, v in sorted(d.items()):\n",
    "            out_list.append(os.path.join(path,k+ext))\n",
    "    return out_list\n",
    "train_file_list = file_dict_to_list(train_dict, raw_out_path)\n",
    "#print(train_file_list)\n",
    "train_raw_features, train_list = load_npy_files(train_file_list)\n",
    "channel_weights = get_discriminative_fm(train_raw_features)\n",
    "\n",
    "def weighting_features(raw_features, weights,out_path = None, save_features = False):\n",
    "    pass\n",
    "    out_features = None\n",
    "    if out_path is not None and not os.path.exists(out_path):\n",
    "        os.makedirs(out_path)\n",
    "    for i,f in enumerate(raw_features):\n",
    "        cvt_raw_feature = covert_data_format(f)  # C x H x W\n",
    "        pwa_feature = PWA(cvt_raw_feature, weights)\n",
    "        if save_features:\n",
    "            np.save(os.path.join(out_path,os.path.basename(raw_files[i])), pwa_feature)\n",
    "        if out_features is None:\n",
    "            out_features = pwa_feature\n",
    "        else:\n",
    "            out_features = np.vstack([out_features, pwa_feature])\n",
    "    return out_features\n",
    "\n",
    "train_features = weighting_features(train_raw_features, channel_weights)\n",
    "print(\"train features shape {}\".format(train_features.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful loading of npy file !!!\n",
      "query features shape (50, 12288)\n"
     ]
    }
   ],
   "source": [
    "query_file_list = file_dict_to_list(query_dict, raw_out_path)\n",
    "query_raw_features, query_list = load_npy_files(query_file_list)\n",
    "query_features = weighting_features(query_raw_features, channel_weights)\n",
    "print(\"query features shape {}\".format(query_features.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP 0.521667\n"
     ]
    }
   ],
   "source": [
    "#query mAP\n",
    "from cbir.utils import result_precision\n",
    "\n",
    "def path_to_list(path_list):\n",
    "    return [os.basename(i).splitext()[0] for i in path_list]\n",
    "\n",
    "#query_files = path_to_list(query_file_list)\n",
    "def query(query, train, gt_dict, topK = 3):\n",
    "    aps=list()\n",
    "    for i in range(len(query)):\n",
    "        idxs, rank_dists, rank_names = compute_cosin_distance([query[i]], \n",
    "                                                          train, train_list)\n",
    "        pos,neg = get_list_set(query_list[i].split('-')[0], gt_dict, delimiter = '-')\n",
    "        pos.remove(query_list[i])\n",
    "        #print(pos)\n",
    "        #ap = result_precision(pos, rank_names[:topK])\n",
    "        ap = compute_ap(pos,rank_names[:topK])\n",
    "        #print(query_list[i], rank_names[:5], ap)\n",
    "        #print(ap)\n",
    "        aps.append(ap)\n",
    "    return aps\n",
    "\n",
    "aps = query(query_features, train_features, gt_dict, topK=3)\n",
    "print('mAP %f' % (np.array(aps).sum()/len(aps),))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mAP 0 0.000\n",
      "mAP 1 0.227\n",
      "mAP 2 0.428\n",
      "mAP 3 0.522\n",
      "mAP 4 0.559\n",
      "mAP 5 0.567\n",
      "mAP 6 0.578\n",
      "mAP 7 0.584\n",
      "mAP 8 0.586\n",
      "mAP 9 0.610\n",
      "mAP 10 0.618\n",
      "mAP 11 0.629\n",
      "mAP 12 0.630\n",
      "mAP 13 0.638\n",
      "mAP 14 0.638\n",
      "mAP 15 0.640\n",
      "mAP 16 0.640\n",
      "mAP 17 0.647\n",
      "mAP 18 0.651\n",
      "mAP 19 0.651\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "for i in range(20):\n",
    "    aps = query(query_features, train_features, gt_dict, topK=i)\n",
    "    print('mAP {} {:.3f}'.format(i,np.array(aps).sum()/len(aps),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
